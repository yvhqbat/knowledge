## kafka是如何保证消息的可靠性传输？
即消息不丢失

答： 可以从3个方面来回答，Kafka/producer/consumer

1. broker配置，有3个参数会影响 Kafka 消息存储的可靠性：复制系数/不完全的首领选举/最少同步副本
   1.1 复制系数N,在N-1个broker宕机的情况下，仍然可用；需要权衡磁盘空间和可用性；
   1.2 不完全的首领选举，（当分区首领不可用时，一个同步副本会被选为新首领。如果提交的数据存在与所有的副本中，选举新首领就是完全的。）如果允许不同步的副本成为首领，就有数据丢失和数据不一致的风险；
   1.3 最少同步副本，根据Kafka对可靠性保证的定义，消息只有在被写入到所有副本之后，才被认为是已提交；
2. 在可靠的系统里使用生产者 producer
   2.1 根据可靠性需求配置适当的 acks (发送确认，有三种不同的确认模式：0/1/all)
   2.2 配置生产者的重试次数；
   2.3 额外的错误处理（重试机制的补充）；
3. 在可靠的系统里使用消费者 consumer
   消费者唯一要做的是跟踪哪些消息是已经读取过的，哪些消息还没有读取的，这是消息不丢失的关键。
   使用偏移量，消费者需要重视偏移量提交的时间和提交方式。
   3.1 自动提交，需要配置 group.id/auto.offset.reset/enable.auto.commit/auto.commit.interval.ms
   3.2 显示提交
   需要注意重复消费的问题

参考：
- [【消息队列】如何处理消息丢失的问题](https://www.cnblogs.com/756623607-zhang/p/10507267.html)
